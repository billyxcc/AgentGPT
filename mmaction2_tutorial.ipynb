{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billyxcc/AgentGPT/blob/main/mmaction2_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjSRFELVbNk"
      },
      "source": [
        "# MMAction2 Tutorial\n",
        "\n",
        "Welcome to MMAction2! This is the official colab tutorial for using MMAction2. In this tutorial, you will learn\n",
        "- Perform inference with a MMAction2 recognizer.\n",
        "- Train a new recognizer with a new dataset.\n",
        "\n",
        "\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## Install MMAction2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf8PpPXtVvmg",
        "outputId": "f792c772-c0b5-4847-e8cd-ca67b6e6f0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZPwKGzqydnb2",
        "outputId": "aa5e4184-c537-4be6-d844-0c88b940c67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (if your colab has CUDA 11.8)\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PAJ4ArzV5Ry",
        "outputId": "3758d610-9b8d-432c-d982-817778efec88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m975.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.6)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.9-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.4)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Installing collected packages: pycryptodome, ordered-set, colorama, model-index, opendatalab, openmim\n",
            "Successfully installed colorama-0.4.6 model-index-0.1.11 opendatalab-0.0.9 openmim-0.3.9 ordered-set-4.1.0 pycryptodome-3.18.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.8.2-py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.22.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.7.0.72)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.14.0)\n",
            "Collecting importlib-metadata>=6.6.0 (from yapf->mmengine)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (3.9.1)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.16.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, importlib-metadata, yapf, mmengine\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed addict-2.4.0 importlib-metadata-6.8.0 mmengine-0.8.2 yapf-0.40.1\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv>=2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.40.1)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (4.7.0.72)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (3.9.1)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0) (3.16.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.1\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22304, done.\u001b[K\n",
            "remote: Counting objects: 100% (1382/1382), done.\u001b[K\n",
            "remote: Compressing objects: 100% (851/851), done.\u001b[K\n",
            "remote: Total 22304 (delta 703), reused 1037 (delta 511), pack-reused 20922\u001b[K\n",
            "Receiving objects: 100% (22304/22304), 69.41 MiB | 34.47 MiB/s, done.\n",
            "Resolving deltas: 100% (15532/15532), done.\n",
            "/content/mmaction2\n",
            "Obtaining file:///content/mmaction2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.1.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.1.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->mmaction2==1.1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->mmaction2==1.1.0) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.1.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.1.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed decord-0.6.0 einops-0.6.1 mmaction2-1.1.0\n",
            "Collecting av>=9.0 (from -r requirements/optional.txt (line 1))\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 2)) (0.18.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 4)) (0.10.0.post2)\n",
            "Collecting lmdb (from -r requirements/optional.txt (line 5))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 6)) (1.0.3)\n",
            "Collecting openai-clip (from -r requirements/optional.txt (line 7))\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 8)) (23.1)\n",
            "Collecting pims (from -r requirements/optional.txt (line 9))\n",
            "  Downloading PIMS-0.6.1.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyTurboJPEG (from -r requirements/optional.txt (line 10))\n",
            "  Downloading PyTurboJPEG-1.7.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements/optional.txt (line 12)) (2.12.3)\n",
            "Collecting wandb (from -r requirements/optional.txt (line 13))\n",
            "  Downloading wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.25.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.56.4)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (0.1.10)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (0.4.8)\n",
            "Collecting ftfy (from openai-clip->-r requirements/optional.txt (line 7))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip->-r requirements/optional.txt (line 7)) (2022.10.31)\n",
            "Collecting slicerator>=0.9.8 (from pims->-r requirements/optional.txt (line 9))\n",
            "  Downloading slicerator-1.1.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements/optional.txt (line 11)) (1.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements/optional.txt (line 12)) (0.41.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading sentry_sdk-1.28.1-py2.py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (6.0.1)\n",
            "Collecting pathtools (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements/optional.txt (line 13)) (1.4.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements/optional.txt (line 11)) (2.21)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements/optional.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r requirements/optional.txt (line 4)) (0.39.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->-r requirements/optional.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (2023.7.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements/optional.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements/optional.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip->-r requirements/optional.txt (line 7)) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements/optional.txt (line 13))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements/optional.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements/optional.txt (line 12)) (3.2.2)\n",
            "Building wheels for collected packages: openai-clip, pims, PyTurboJPEG, pathtools\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=52ceac639f0b7cef3bb0c419d540719a5ee3738d9cbcb3117f37551faa26e7fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "  Building wheel for pims (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pims: filename=PIMS-0.6.1-py3-none-any.whl size=82618 sha256=69b2f6461b7941075749412572d357ee3897586a257d800e6195c589ca3c9d6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\n",
            "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.7.2-py3-none-any.whl size=12248 sha256=8e7389eae3c59a27d36d7f5e73d31bbf9a323ddf790282625d2ddcf4afc26dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/d0/35/e1c861364e31ba4d416bf5fa6ee1c3927c06c899a0d3b5beb4\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=9cd615ced1c67abb05aa9910802835573d1378729f4a67077d767be3104ec34b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built openai-clip pims PyTurboJPEG pathtools\n",
            "Installing collected packages: slicerator, pathtools, lmdb, av, smmap, setproctitle, sentry-sdk, PyTurboJPEG, ftfy, docker-pycreds, pims, openai-clip, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.32 PyTurboJPEG-1.7.2 av-10.0.0 docker-pycreds-0.4.0 ftfy-6.1.1 gitdb-4.0.10 lmdb-1.4.1 openai-clip-1.0.1 pathtools-0.1.2 pims-0.6.1 sentry-sdk-1.28.1 setproctitle-1.3.2 slicerator-1.1.0 smmap-5.0.0 wandb-0.15.7\n"
          ]
        }
      ],
      "source": [
        "# install MMEngine, MMCV and MMDetection using MIM\n",
        "%pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmcv>=2.0.0\"\n",
        "\n",
        "# Install mmaction2\n",
        "!rm -rf mmaction2\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git -b main\n",
        "%cd mmaction2\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# Install some optional requirements\n",
        "!pip install -r requirements/optional.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No_zZAFpWC-a",
        "outputId": "11c2885b-70b2-4674-dcc8-bb78c2574bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118 True\n",
            "1.1.0\n",
            "11.8\n",
            "GCC 9.3\n",
            "OrderedDict([('sys.platform', 'linux'), ('Python', '3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]'), ('CUDA available', True), ('numpy_random_seed', 2147483648), ('GPU 0', 'Tesla T4'), ('CUDA_HOME', '/usr/local/cuda'), ('NVCC', 'Cuda compilation tools, release 11.8, V11.8.89'), ('GCC', 'x86_64-linux-gnu-gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0'), ('PyTorch', '2.0.1+cu118'), ('PyTorch compiling details', 'PyTorch built with:\\n  - GCC 9.3\\n  - C++ Version: 201703\\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.8\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 8.7\\n  - Magma 2.6.1\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \\n'), ('TorchVision', '0.15.2+cu118'), ('OpenCV', '4.7.0'), ('MMEngine', '0.8.2')])\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMEngine installation\n",
        "from mmengine.utils.dl_utils import collect_env\n",
        "print(collect_env())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inpeme"
      ],
      "metadata": {
        "id": "GTL5BZ_Qf2vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "import decord\n",
        "import numpy as np\n",
        "from mmcv.transforms import TRANSFORMS, BaseTransform, to_tensor\n",
        "from mmaction.structures import ActionDataSample\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoInit(BaseTransform):\n",
        "    def transform(self, results):\n",
        "        container = decord.VideoReader(results['filename'])\n",
        "        results['total_frames'] = len(container)\n",
        "        results['video_reader'] = container\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoSample(BaseTransform):\n",
        "    def __init__(self, clip_len, num_clips, test_mode=False):\n",
        "        self.clip_len = clip_len\n",
        "        self.num_clips = num_clips\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "    def transform(self, results):\n",
        "        total_frames = results['total_frames']\n",
        "        interval = total_frames // self.clip_len\n",
        "\n",
        "        if self.test_mode:\n",
        "            # Make the sampling during testing deterministic\n",
        "            np.random.seed(42)\n",
        "\n",
        "        inds_of_all_clips = []\n",
        "        for i in range(self.num_clips):\n",
        "            bids = np.arange(self.clip_len) * interval\n",
        "            offset = np.random.randint(interval, size=bids.shape)\n",
        "            inds = bids + offset\n",
        "            inds_of_all_clips.append(inds)\n",
        "\n",
        "        results['frame_inds'] = np.concatenate(inds_of_all_clips)\n",
        "        results['clip_len'] = self.clip_len\n",
        "        results['num_clips'] = self.num_clips\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoDecode(BaseTransform):\n",
        "    def transform(self, results):\n",
        "        frame_inds = results['frame_inds']\n",
        "        container = results['video_reader']\n",
        "\n",
        "        imgs = container.get_batch(frame_inds).asnumpy()\n",
        "        imgs = list(imgs)\n",
        "\n",
        "        results['video_reader'] = None\n",
        "        del container\n",
        "\n",
        "        results['imgs'] = imgs\n",
        "        results['img_shape'] = imgs[0].shape[:2]\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoResize(BaseTransform):\n",
        "    def __init__(self, r_size):\n",
        "        self.r_size = (np.inf, r_size)\n",
        "\n",
        "    def transform(self, results):\n",
        "        img_h, img_w = results['img_shape']\n",
        "        new_w, new_h = mmcv.rescale_size((img_w, img_h), self.r_size)\n",
        "\n",
        "        imgs = [mmcv.imresize(img, (new_w, new_h))\n",
        "                for img in results['imgs']]\n",
        "        results['imgs'] = imgs\n",
        "        results['img_shape'] = imgs[0].shape[:2]\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoCrop(BaseTransform):\n",
        "    def __init__(self, c_size):\n",
        "        self.c_size = c_size\n",
        "\n",
        "    def transform(self, results):\n",
        "        img_h, img_w = results['img_shape']\n",
        "        center_x, center_y = img_w // 2, img_h // 2\n",
        "        x1, x2 = center_x - self.c_size // 2, center_x + self.c_size // 2\n",
        "        y1, y2 = center_y - self.c_size // 2, center_y + self.c_size // 2\n",
        "        imgs = [img[y1:y2, x1:x2] for img in results['imgs']]\n",
        "        results['imgs'] = imgs\n",
        "        results['img_shape'] = imgs[0].shape[:2]\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoFormat(BaseTransform):\n",
        "    def transform(self, results):\n",
        "        num_clips = results['num_clips']\n",
        "        clip_len = results['clip_len']\n",
        "        imgs = results['imgs']\n",
        "\n",
        "        # [num_clips*clip_len, H, W, C]\n",
        "        imgs = np.array(imgs)\n",
        "        # [num_clips, clip_len, H, W, C]\n",
        "        imgs = imgs.reshape((num_clips, clip_len) + imgs.shape[1:])\n",
        "        # [num_clips, C, clip_len, H, W]\n",
        "        imgs = imgs.transpose(0, 4, 1, 2, 3)\n",
        "\n",
        "        results['imgs'] = imgs\n",
        "        return results\n",
        "\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class VideoPack(BaseTransform):\n",
        "    def __init__(self, meta_keys=('img_shape', 'num_clips', 'clip_len')):\n",
        "        self.meta_keys = meta_keys\n",
        "\n",
        "    def transform(self, results):\n",
        "        packed_results = dict()\n",
        "        inputs = to_tensor(results['imgs'])\n",
        "        data_sample = ActionDataSample().set_gt_labels(results['label'])\n",
        "        metainfo = {k: results[k] for k in self.meta_keys if k in results}\n",
        "        data_sample.set_metainfo(metainfo)\n",
        "        packed_results['inputs'] = inputs\n",
        "        packed_results['data_samples'] = data_sample\n",
        "        return packed_results"
      ],
      "metadata": {
        "id": "Nit5_ZK4f2Vq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "from mmengine.dataset import Compose\n",
        "\n",
        "pipeline_cfg = [\n",
        "    dict(type='VideoInit'),\n",
        "    dict(type='VideoSample', clip_len=16, num_clips=1, test_mode=False),\n",
        "    dict(type='VideoDecode'),\n",
        "    dict(type='VideoResize', r_size=256),\n",
        "    dict(type='VideoCrop', c_size=224),\n",
        "    dict(type='VideoFormat'),\n",
        "    dict(type='VideoPack')\n",
        "]\n",
        "pipeline = Compose(pipeline_cfg)\n",
        "data_prefix = '/content/drive/MyDrive/dataset/val'\n",
        "results = dict(filename=osp.join(data_prefix, '/content/drive/MyDrive/dataset/val/body_drinking_2019-03-08-09;31;15_0.mp4'), label=0)\n",
        "packed_results = pipeline(results)\n",
        "\n",
        "inputs = packed_results['inputs']\n",
        "data_sample = packed_results['data_samples']\n",
        "\n",
        "print('shape of the inputs: ', inputs.shape)\n",
        "\n",
        "# Get metainfo of the inputs\n",
        "print('image_shape: ', data_sample.img_shape)\n",
        "print('num_clips: ', data_sample.num_clips)\n",
        "print('clip_len: ', data_sample.clip_len)\n",
        "\n",
        "# Get label of the inputs\n",
        "print('label: ', data_sample.gt_labels.item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to4w8cR5gD2J",
        "outputId": "0ef1ed35-45aa-48db-c920-37a7eaa96dab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the inputs:  torch.Size([1, 3, 16, 224, 224])\n",
            "image_shape:  (224, 224)\n",
            "num_clips:  1\n",
            "clip_len:  16\n",
            "label:  tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "from typing import Callable, List, Optional, Union\n",
        "\n",
        "from mmengine.fileio import exists, list_from_file\n",
        "\n",
        "from mmaction.registry import DATASETS\n",
        "from mmaction.utils import ConfigType\n",
        "from .base import BaseActionDataset\n",
        "\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class VideoDataset(BaseDataset):\n",
        "   def __init__(self,\n",
        "                 ann_file: str,\n",
        "                 pipeline: List[Union[dict, Callable]],\n",
        "                 data_prefix: ConfigType = dict(video=''),\n",
        "                 multi_class: bool = False,\n",
        "                 num_classes: Optional[int] = None,\n",
        "                 start_index: int = 0,\n",
        "                 modality: str = 'RGB',\n",
        "                 test_mode: bool = False,\n",
        "                 delimiter: str = ' ',\n",
        "                 **kwargs) -> None:\n",
        "        self.delimiter = delimiter\n",
        "        super().__init__(\n",
        "            ann_file,\n",
        "            pipeline=pipeline,\n",
        "            data_prefix=data_prefix,\n",
        "            multi_class=multi_class,\n",
        "            num_classes=num_classes,\n",
        "            start_index=start_index,\n",
        "            modality=modality,\n",
        "            test_mode=test_mode,\n",
        "            **kwargs)\n",
        "\n",
        "    def load_data_list(self) -> List[dict]:\n",
        "        \"\"\"Load annotation file to get video information.\"\"\"\n",
        "        exists(self.ann_file)\n",
        "        data_list = []\n",
        "        fin = list_from_file(self.ann_file)\n",
        "        for line in fin:\n",
        "            line_split = line.strip().split(self.delimiter)\n",
        "            if self.multi_class:\n",
        "                assert self.num_classes is not None\n",
        "                filename, label = line_split[0], line_split[1:]\n",
        "                label = list(map(int, label))\n",
        "            # add fake label for inference datalist without label\n",
        "            elif len(line_split) == 1:\n",
        "                filename, label = line_split[0], -1\n",
        "            else:\n",
        "                filename, label = line_split\n",
        "                label = int(label)\n",
        "            if self.data_prefix['video'] is not None:\n",
        "                filename = osp.join(self.data_prefix['video'], filename)\n",
        "            data_list.append(dict(filename=filename, label=label))\n",
        "        return data_list"
      ],
      "metadata": {
        "id": "TJaQmHVmi1F9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "d5eda040-e3f7-4d17-d3ad-44611660953b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    def load_data_list(self) -> List[dict]:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmaction.registry import DATASETS\n",
        "\n",
        "train_pipeline_cfg = [\n",
        "    dict(type='VideoInit'),\n",
        "    dict(type='VideoSample', clip_len=16, num_clips=1, test_mode=False),\n",
        "    dict(type='VideoDecode'),\n",
        "    dict(type='VideoResize', r_size=256),\n",
        "    dict(type='VideoCrop', c_size=224),\n",
        "    dict(type='VideoFormat'),\n",
        "    dict(type='VideoPack')\n",
        "]\n",
        "\n",
        "val_pipeline_cfg = [\n",
        "    dict(type='VideoInit'),\n",
        "    dict(type='VideoSample', clip_len=16, num_clips=5, test_mode=True),\n",
        "    dict(type='VideoDecode'),\n",
        "    dict(type='VideoResize', r_size=256),\n",
        "    dict(type='VideoCrop', c_size=224),\n",
        "    dict(type='VideoFormat'),\n",
        "    dict(type='VideoPack')\n",
        "]\n",
        "\n",
        "train_dataset_cfg = dict(\n",
        "    type='VideoDataset',\n",
        "    ann_file='/content/drive/MyDrive/dataset/train.txt',\n",
        "    pipeline=train_pipeline_cfg,\n",
        "    data_root='/content/drive/MyDrive/dataset',\n",
        "    data_prefix=dict(video='train'))\n",
        "\n",
        "val_dataset_cfg = dict(\n",
        "    type='VideoDataset',\n",
        "    ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
        "    pipeline=val_pipeline_cfg,\n",
        "    data_root='/content/drive/MyDrive/dataset',\n",
        "    data_prefix=dict(video='val'))\n",
        "\n",
        "train_dataset = DATASETS.build(train_dataset_cfg)\n",
        "\n",
        "packed_results = train_dataset[0]\n",
        "\n",
        "inputs = packed_results['inputs']\n",
        "data_sample = packed_results['data_samples']\n",
        "\n",
        "print('shape of the inputs: ', inputs.shape)\n",
        "\n",
        "# Get metainfo of the inputs\n",
        "print('image_shape: ', data_sample.img_shape)\n",
        "print('num_clips: ', data_sample.num_clips)\n",
        "print('clip_len: ', data_sample.clip_len)\n",
        "\n",
        "# Get label of the inputs\n",
        "print('label: ', data_sample.gt_labels.item)\n",
        "\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "train_dataloader_cfg = dict(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=0,\n",
        "    persistent_workers=False,\n",
        "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
        "    dataset=train_dataset_cfg)\n",
        "\n",
        "val_dataloader_cfg = dict(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=0,\n",
        "    persistent_workers=False,\n",
        "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
        "    dataset=val_dataset_cfg)\n",
        "\n",
        "train_data_loader = Runner.build_dataloader(dataloader=train_dataloader_cfg)\n",
        "val_data_loader = Runner.build_dataloader(dataloader=val_dataloader_cfg)\n",
        "\n",
        "batched_packed_results = next(iter(train_data_loader))\n",
        "\n",
        "batched_inputs = batched_packed_results['inputs']\n",
        "batched_data_sample = batched_packed_results['data_samples']\n",
        "\n",
        "assert len(batched_inputs) == BATCH_SIZE\n",
        "assert len(batched_data_sample) == BATCH_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "X7Jx1QWvjFzr",
        "outputId": "402b0a7e-537a-48e2-abc5-154a2efdb72d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the inputs:  torch.Size([1, 3, 16, 224, 224])\n",
            "image_shape:  (224, 224)\n",
            "num_clips:  1\n",
            "clip_len:  16\n",
            "label:  tensor([0])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d3be36f5c3b2>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     dataset=val_dataset_cfg)\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mbuild_dataloader\u001b[0;34m(dataloader, seed, diff_rank_seed)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mdataset_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full_init'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/registry/registry.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \"\"\"\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Registry'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/registry/build_functions.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mobj_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;34mf'{obj_type} is not in the {registry.name} registry. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;34mf'Please check whether the value of `{obj_type}` is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'DatasetZelda is not in the dataset registry. Please check whether the value of `DatasetZelda` is correct or it was registered as expected. More details can be found at https://mmengine.readthedocs.io/en/latest/advanced_tutorials/config.html#import-the-custom-module'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mmengine.model import BaseDataPreprocessor, stack_batch\n",
        "from mmaction.registry import MODELS\n",
        "\n",
        "\n",
        "@MODELS.register_module()\n",
        "class DataPreprocessorZelda(BaseDataPreprocessor):\n",
        "    def __init__(self, mean, std):\n",
        "        super().__init__()\n",
        "\n",
        "        self.register_buffer(\n",
        "            'mean',\n",
        "            torch.tensor(mean, dtype=torch.float32).view(-1, 1, 1, 1),\n",
        "            False)\n",
        "        self.register_buffer(\n",
        "            'std',\n",
        "            torch.tensor(std, dtype=torch.float32).view(-1, 1, 1, 1),\n",
        "            False)\n",
        "\n",
        "    def forward(self, data, training=False):\n",
        "        data = self.cast_data(data)\n",
        "        inputs = data['inputs']\n",
        "        batch_inputs = stack_batch(inputs)  # Batching\n",
        "        batch_inputs = (batch_inputs - self.mean) / self.std  # Normalization\n",
        "        data['inputs'] = batch_inputs\n",
        "        return data"
      ],
      "metadata": {
        "id": "iwCKsGgBnChA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mmaction.registry import MODELS\n",
        "\n",
        "data_preprocessor_cfg = dict(\n",
        "    type='DataPreprocessorZelda',\n",
        "    mean=[123.675, 116.28, 103.53],\n",
        "    std=[58.395, 57.12, 57.375])\n",
        "\n",
        "data_preprocessor = MODELS.build(data_preprocessor_cfg)\n",
        "\n",
        "preprocessed_inputs = data_preprocessor(batched_packed_results)\n",
        "print(preprocessed_inputs['inputs'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6R4lMIWnKag",
        "outputId": "bf40a59d-b203-4ad4-d327-32f618fd241a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 3, 16, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from mmengine.model import BaseModel, BaseModule, Sequential\n",
        "from mmengine.structures import LabelData\n",
        "from mmaction.registry import MODELS\n",
        "\n",
        "\n",
        "@MODELS.register_module()\n",
        "class BackBoneZelda(BaseModule):\n",
        "    def __init__(self, init_cfg=None):\n",
        "        if init_cfg is None:\n",
        "            init_cfg = [dict(type='Kaiming', layer='Conv3d', mode='fan_out', nonlinearity=\"relu\"),\n",
        "                        dict(type='Constant', layer='BatchNorm3d', val=1, bias=0)]\n",
        "\n",
        "        super(BackBoneZelda, self).__init__(init_cfg=init_cfg)\n",
        "\n",
        "        self.conv1 = Sequential(nn.Conv3d(3, 64, kernel_size=(3, 7, 7),\n",
        "                                          stride=(1, 2, 2), padding=(1, 3, 3)),\n",
        "                                nn.BatchNorm3d(64), nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2),\n",
        "                                    padding=(0, 1, 1))\n",
        "\n",
        "        self.conv = Sequential(nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "                               nn.BatchNorm3d(128), nn.ReLU())\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # imgs: [batch_size*num_views, 3, T, H, W]\n",
        "        # features: [batch_size*num_views, 128, T/2, H//8, W//8]\n",
        "        features = self.conv(self.maxpool(self.conv1(imgs)))\n",
        "        return features\n",
        "\n",
        "\n",
        "@MODELS.register_module()\n",
        "class ClsHeadZelda(BaseModule):\n",
        "    def __init__(self, num_classes, in_channels, dropout=0.5, average_clips='prob', init_cfg=None):\n",
        "        if init_cfg is None:\n",
        "            init_cfg = dict(type='Normal', layer='Linear', std=0.01)\n",
        "\n",
        "        super(ClsHeadZelda, self).__init__(init_cfg=init_cfg)\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.in_channels = in_channels\n",
        "        self.average_clips = average_clips\n",
        "\n",
        "        if dropout != 0:\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.dropout = None\n",
        "\n",
        "        self.fc = nn.Linear(self.in_channels, self.num_classes)\n",
        "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, H, W = x.shape\n",
        "        x = self.pool(x)\n",
        "        x = x.view(N, C)\n",
        "        assert x.shape[1] == self.in_channels\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        cls_scores = self.fc(x)\n",
        "        return cls_scores\n",
        "\n",
        "    def loss(self, feats, data_samples):\n",
        "        cls_scores = self(feats)\n",
        "        labels = torch.stack([x.gt_labels.item for x in data_samples])\n",
        "        labels = labels.squeeze()\n",
        "\n",
        "        if labels.shape == torch.Size([]):\n",
        "            labels = labels.unsqueeze(0)\n",
        "\n",
        "        loss_cls = self.loss_fn(cls_scores, labels)\n",
        "        return dict(loss_cls=loss_cls)\n",
        "\n",
        "    def predict(self, feats, data_samples):\n",
        "        cls_scores = self(feats)\n",
        "        num_views = cls_scores.shape[0] // len(data_samples)\n",
        "        # assert num_views == data_samples[0].num_clips\n",
        "        cls_scores = self.average_clip(cls_scores, num_views)\n",
        "\n",
        "        for ds, sc in zip(data_samples, cls_scores):\n",
        "            pred = LabelData(item=sc)\n",
        "            ds.pred_scores = pred\n",
        "        return data_samples\n",
        "\n",
        "    def average_clip(self, cls_scores, num_views):\n",
        "          if self.average_clips not in ['score', 'prob', None]:\n",
        "            raise ValueError(f'{self.average_clips} is not supported. '\n",
        "                             f'Currently supported ones are '\n",
        "                             f'[\"score\", \"prob\", None]')\n",
        "\n",
        "          total_views = cls_scores.shape[0]\n",
        "          cls_scores = cls_scores.view(total_views // num_views, num_views, -1)\n",
        "\n",
        "          if self.average_clips is None:\n",
        "              return cls_scores\n",
        "          elif self.average_clips == 'prob':\n",
        "              cls_scores = F.softmax(cls_scores, dim=2).mean(dim=1)\n",
        "          elif self.average_clips == 'score':\n",
        "              cls_scores = cls_scores.mean(dim=1)\n",
        "\n",
        "          return cls_scores\n",
        "\n",
        "\n",
        "@MODELS.register_module()\n",
        "class RecognizerZelda(BaseModel):\n",
        "    def __init__(self, backbone, cls_head, data_preprocessor):\n",
        "        super().__init__(data_preprocessor=data_preprocessor)\n",
        "\n",
        "        self.backbone = MODELS.build(backbone)\n",
        "        self.cls_head = MODELS.build(cls_head)\n",
        "\n",
        "    def extract_feat(self, inputs):\n",
        "        inputs = inputs.view((-1, ) + inputs.shape[2:])\n",
        "        return self.backbone(inputs)\n",
        "\n",
        "    def loss(self, inputs, data_samples):\n",
        "        feats = self.extract_feat(inputs)\n",
        "        loss = self.cls_head.loss(feats, data_samples)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, inputs, data_samples):\n",
        "        feats = self.extract_feat(inputs)\n",
        "        predictions = self.cls_head.predict(feats, data_samples)\n",
        "        return predictions\n",
        "\n",
        "    def forward(self, inputs, data_samples=None, mode='tensor'):\n",
        "        if mode == 'tensor':\n",
        "            return self.extract_feat(inputs)\n",
        "        elif mode == 'loss':\n",
        "            return self.loss(inputs, data_samples)\n",
        "        elif mode == 'predict':\n",
        "            return self.predict(inputs, data_samples)\n",
        "        else:\n",
        "            raise RuntimeError(f'Invalid mode: {mode}')"
      ],
      "metadata": {
        "id": "dG3SMKmAnP53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import copy\n",
        "from mmaction.registry import MODELS\n",
        "\n",
        "model_cfg = dict(\n",
        "    type='RecognizerZelda',\n",
        "    backbone=dict(type='BackBoneZelda'),\n",
        "    cls_head=dict(\n",
        "        type='ClsHeadZelda',\n",
        "        num_classes=2,\n",
        "        in_channels=128,\n",
        "        average_clips='prob'),\n",
        "    data_preprocessor = dict(\n",
        "        type='DataPreprocessorZelda',\n",
        "        mean=[123.675, 116.28, 103.53],\n",
        "        std=[58.395, 57.12, 57.375]))\n",
        "\n",
        "model = MODELS.build(model_cfg)\n",
        "\n",
        "# Train\n",
        "model.train()\n",
        "model.init_weights()\n",
        "data_batch_train = copy.deepcopy(batched_packed_results)\n",
        "data = model.data_preprocessor(data_batch_train, training=True)\n",
        "loss = model(**data, mode='loss')\n",
        "print('loss dict: ', loss)\n",
        "\n",
        "# Test\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    data_batch_test = copy.deepcopy(batched_packed_results)\n",
        "    data = model.data_preprocessor(data_batch_test, training=False)\n",
        "    predictions = model(**data, mode='predict')\n",
        "print('Label of Sample[0]', predictions[0].gt_labels.item)\n",
        "print('Scores of Sample[0]', predictions[0].pred_scores.item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "owJJfmIOnWvY",
        "outputId": "4dc4cd81-b331-410e-8594-74afbff4ab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv1.0.weight - torch.Size([64, 3, 3, 7, 7]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv1.0.bias - torch.Size([64]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv1.1.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of RecognizerZelda  \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv1.1.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of RecognizerZelda  \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv.0.weight - torch.Size([128, 64, 3, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv.0.bias - torch.Size([128]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv.1.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of RecognizerZelda  \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "backbone.conv.1.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of RecognizerZelda  \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "cls_head.fc.weight - torch.Size([2, 128]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "07/27 09:12:49 - mmengine - INFO - \n",
            "cls_head.fc.bias - torch.Size([2]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ebcfea9b5b0c>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata_batch_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_packed_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss dict: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-c19d1f27ca16>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-c19d1f27ca16>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, inputs, data_samples)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-c19d1f27ca16>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, feats, data_samples)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mloss_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 4 is out of bounds."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "## Perform inference with a MMAction2 recognizer\n",
        "MMAction2 already provides high level APIs to do inference and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64CW6d_AaT-Q",
        "outputId": "651d80f5-8a17-4a93-b494-f3147e6b8d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-28 01:38:51--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 8.25.82.207, 8.25.82.211, 8.25.82.214, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|8.25.82.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97579339 (93M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’\n",
            "\n",
            "checkpoints/tsn_r50 100%[===================>]  93.06M  14.8MB/s    in 6.8s    \n",
            "\n",
            "2023-07-28 01:38:59 (13.7 MB/s) - ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’ saved [97579339/97579339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
        "      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNZB7NoSabzj",
        "outputId": "f4dd6851-7992-486a-b254-809c0e98dc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n"
          ]
        }
      ],
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "from mmengine import Config\n",
        "\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = 'configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'\n",
        "config = Config.fromfile(config)\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "outputs": [],
      "source": [
        "# Use the recognizer to do inference\n",
        "from operator import itemgetter\n",
        "video = '/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-09;31;15_1.mp4'\n",
        "label = 'tools/data/kinetics/label_map_k400.txt'\n",
        "results = inference_recognizer(model, video)\n",
        "\n",
        "pred_scores = results.pred_scores.item.tolist()\n",
        "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
        "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
        "top5_label = score_sorted[:5]\n",
        "\n",
        "labels = open(label).readlines()\n",
        "labels = [x.strip() for x in labels]\n",
        "results = [(labels[k[0]], k[1]) for k in top5_label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIyJXqfWathq",
        "outputId": "f9ca4f96-b5a5-4a17-bfb8-ec787e12c77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top-5 labels with corresponding scores are:\n",
            "eating chips:  0.17291980981826782\n",
            "texting:  0.15836068987846375\n",
            "smoking:  0.08062934875488281\n",
            "drinking:  0.07942352443933487\n",
            "eating burger:  0.07657662779092789\n"
          ]
        }
      ],
      "source": [
        "print('The top-5 labels with corresponding scores are:')\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## Train a recognizer on customized dataset\n",
        "\n",
        "To train a new recognizer, there are usually three things to do:\n",
        "1. Support a new dataset\n",
        "2. Modify the config\n",
        "3. Train a new recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEFyxChfgiJ"
      },
      "source": [
        "### Support a new dataset\n",
        "\n",
        "In this tutorial, we gives an example to convert the data into the format of existing datasets. Other methods and more advanced usages can be found in the [doc](/docs/tutorials/new_dataset.md)\n",
        "\n",
        "Firstly, let's download a tiny dataset obtained from [Kinetics-400](https://deepmind.com/research/open-source/open-source-datasets/kinetics/). We select 30 videos with their labels as train dataset and 10 videos with their labels as test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjsUj9JzgUlJ",
        "outputId": "9293c49a-33a6-4ebe-f96a-d7a811d3b94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-27 08:04:44--  https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.246.20.227, 47.246.20.230, 47.246.20.229, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.246.20.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18308682 (17M) [application/zip]\n",
            "Saving to: ‘kinetics400_tiny.zip’\n",
            "\n",
            "kinetics400_tiny.zi 100%[===================>]  17.46M  10.1MB/s    in 1.7s    \n",
            "\n",
            "2023-07-27 08:04:46 (10.1 MB/s) - ‘kinetics400_tiny.zip’ saved [18308682/18308682]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download, decompress the data\n",
        "!rm kinetics400_tiny.zip*\n",
        "!rm -rf kinetics400_tiny\n",
        "!wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
        "!unzip kinetics400_tiny.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbZ-o7V6hNw4",
        "outputId": "afada81d-6e86-4b3b-e8b1-ec264b762683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "\u001b[01;34m/content/drive/MyDrive/dataset\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-09;31;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-09;31;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-09;31;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-09;31;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;27;38_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;27;38_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;27;38_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;27;38_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;57;00_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;57;00_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;57;00_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;57;00_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;57;00_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;21;03_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;50;49_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;50;49_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;50;49_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;16;48_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;46;46_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-13-10;43;06_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-13-10;43;06_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-09;31;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-09;31;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-09;31;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;01;44_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;01;44_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;01;44_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;27;38_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;27;38_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-13-10;36;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;10;35_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;10;35_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;23;42_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;41;01_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;41;01_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-11;00;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-14-14;31;08_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-14-14;31;08_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_21.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_21.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_21.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_22.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_23.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;27;38_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_21.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-09;10;35_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-09;23;42_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-09;41;01_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-11;00;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-13-11;00;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_19.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_20.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_12.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-09;50;49_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;46;46_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;46;46_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;21;03_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;46;46_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;46;46_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   └── \u001b[00mbody_texting_right_2019-03-13-10;43;06_1.mp4\u001b[0m\n",
            "├── \u001b[00mtrain.txt\u001b[0m\n",
            "├── \u001b[01;34mval\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-09;31;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-08-10;01;44_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_drinking_2019-03-13-10;36;15_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;21;03_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-09;50;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_hair_and_makeup_2019-03-13-10;43;06_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-10;16;48_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_left_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_phonecall_right_2019-03-08-10;46;46_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;01;44_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;01;44_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-08-10;57;00_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_radio_2019-03-13-10;36;15_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-09;23;42_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_backseat_2019-03-13-11;00;49_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_17.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_18.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;21;03_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;31;15_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-09;50;49_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;01;44_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_11.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;16;48_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_13.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;46;46_9.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-08-10;57;00_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-09;10;35_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-09;41;01_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;36;15_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_15.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-10;43;06_16.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_reach_side_2019-03-13-11;00;49_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_standstill_or_waiting_2019-03-13-10;43;06_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-09;31;15_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;01;44_21.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_10.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_14.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_2.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;27;38_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-08-10;57;00_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_4.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_talking_to_passenger_2019-03-13-10;36;15_8.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;16;48_1.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_left_2019-03-08-10;46;46_3.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_5.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_6.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-09;50;49_7.mp4\u001b[0m\n",
            "│   ├── \u001b[00mbody_texting_right_2019-03-08-10;46;46_0.mp4\u001b[0m\n",
            "│   └── \u001b[00mbody_texting_right_2019-03-08-10;46;46_4.mp4\u001b[0m\n",
            "└── \u001b[00mval.txt\u001b[0m\n",
            "\n",
            "2 directories, 371 files\n"
          ]
        }
      ],
      "source": [
        "# Check the directory structure of the tiny data\n",
        "\n",
        "# Install tree first\n",
        "!apt-get -q install tree\n",
        "!tree /content/drive/MyDrive/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTdi6dI0hY3g",
        "outputId": "f80af693-11b7-49f8-bdb2-6b485b1b64b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-09;31;15_2.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-09;31;15_3.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-09;31;15_4.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;01;44_0.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;01;44_2.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;01;44_3.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;01;44_5.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;27;38_0.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;27;38_1.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;27;38_2.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;27;38_3.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;57;00_0.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;57;00_1.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;57;00_2.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;57;00_3.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-10;57;00_4.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-13-10;36;15_0.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-13-10;36;15_3.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-13-10;36;15_4.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-13-10;36;15_5.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-13-10;36;15_6.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_drinking_2019-03-08-09;31;15_1.mp4 0\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;50;49_4.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-10;16;48_0.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-10;16;48_1.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-10;16;48_2.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-10;46;46_0.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-10;46;46_2.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-13-10;43;06_0.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-13-10;43;06_1.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-13-10;43;06_2.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;21;03_1.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;21;03_2.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;50;49_0.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;50;49_2.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_hair_and_makeup_2019-03-08-09;50;49_3.mp4 1\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-10;46;46_1.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-13-10;43;06_0.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-13-10;43;06_1.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-13-10;43;06_2.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-09;21;03_0.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-09;21;03_1.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-09;50;49_0.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-09;50;49_1.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_left_2019-03-08-10;46;46_0.mp4 2\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-09;21;03_0.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-09;21;03_1.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-09;50;49_0.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-09;50;49_1.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-10;16;48_0.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-08-10;16;48_1.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-13-10;43;06_0.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_phonecall_right_2019-03-13-10;43;06_1.mp4 3\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;01;44_3.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;01;44_4.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;27;38_0.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;27;38_1.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_0.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_1.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_2.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_3.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_5.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_6.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;57;00_7.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-13-10;36;15_0.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-09;31;15_0.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-09;31;15_1.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-09;31;15_2.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_radio_2019-03-08-10;01;44_2.mp4 4\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-11;00;49_1.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-14-14;31;08_0.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-14-14;31;08_1.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-09;10;35_0.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-09;10;35_1.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-09;23;42_0.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-09;41;01_0.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_backseat_2019-03-13-09;41;01_1.mp4 5\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_9.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_10.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_11.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_12.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_15.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_16.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_19.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_20.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_21.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;31;15_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_8.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_9.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_10.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_12.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_13.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_15.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_16.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_17.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_18.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_19.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_20.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;50;49_21.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;01;44_8.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_9.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_12.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_14.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_16.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_17.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_18.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_19.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_20.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_21.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_22.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;16;48_23.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;27;38_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_10.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_11.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_12.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_14.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_15.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_16.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_17.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_18.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_19.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_20.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;46;46_21.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-10;57;00_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-09;10;35_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-09;23;42_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-09;41;01_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;36;15_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_2.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_3.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_4.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_5.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_6.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_7.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_8.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_9.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_10.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_11.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_12.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_13.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_14.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_17.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_18.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_19.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-10;43;06_20.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-13-11;00;49_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_0.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_reach_side_2019-03-08-09;21;03_1.mp4 6\r\n",
            "/content/drive/MyDrive/dataset/train/body_standstill_or_waiting_2019-03-13-10;43;06_1.mp4 7\r\n",
            "/content/drive/MyDrive/dataset/train/body_standstill_or_waiting_2019-03-13-11;00;49_0.mp4 7\r\n",
            "/content/drive/MyDrive/dataset/train/body_standstill_or_waiting_2019-03-08-09;50;49_0.mp4 7\r\n",
            "/content/drive/MyDrive/dataset/train/body_standstill_or_waiting_2019-03-08-09;50;49_1.mp4 7\r\n",
            "/content/drive/MyDrive/dataset/train/body_standstill_or_waiting_2019-03-08-10;16;48_0.mp4 7\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_7.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_8.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_9.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_11.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_12.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_13.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_0.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_1.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_2.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_3.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_4.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_5.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_6.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_7.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_8.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_9.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_10.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_11.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_12.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_13.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_14.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_15.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_16.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_17.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_18.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_19.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;01;44_20.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_0.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_1.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_3.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_4.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_5.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_7.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_8.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_9.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_11.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_12.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_13.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_15.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_16.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;27;38_17.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_0.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_1.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_2.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_3.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_5.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_6.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-10;57;00_7.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-13-10;36;15_0.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-13-10;36;15_1.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-13-10;36;15_2.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-13-10;36;15_3.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-13-10;36;15_5.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_1.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_2.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_3.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_talking_to_passenger_2019-03-08-09;31;15_6.mp4 8\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-10;46;46_1.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-10;46;46_2.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-10;46;46_4.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-13-10;43;06_0.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-13-10;43;06_1.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-09;21;03_0.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-09;21;03_1.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-09;50;49_0.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-09;50;49_1.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-09;50;49_2.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_left_2019-03-08-10;16;48_0.mp4 9\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_2.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_3.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_4.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_8.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_9.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_10.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_11.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-10;16;48_0.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-10;16;48_1.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-10;46;46_1.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-10;46;46_2.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-10;46;46_3.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-13-10;43;06_0.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-13-10;43;06_1.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;21;03_0.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;21;03_1.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_0.mp4 10\r\n",
            "/content/drive/MyDrive/dataset/train/body_texting_right_2019-03-08-09;50;49_1.mp4 10"
          ]
        }
      ],
      "source": [
        "# After downloading the data, we need to check the annotation format\n",
        "!cat /content/drive/MyDrive/dataset/train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('./configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8YhFFGjp3e"
      },
      "source": [
        "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhu9byjjt-K",
        "outputId": "3c971649-526a-4e92-e6cc-6c0090543e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01,\n",
            "        average_clips='prob'),\n",
            "    data_preprocessor=dict(\n",
            "        type='ActionDataPreprocessor',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        format_shape='NCHW'),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "train_cfg = dict(\n",
            "    type='EpochBasedTrainLoop', max_epochs=10, val_begin=1, val_interval=1)\n",
            "val_cfg = dict(type='ValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=100,\n",
            "        by_epoch=True,\n",
            "        milestones=[\n",
            "            40,\n",
            "            80,\n",
            "        ],\n",
            "        gamma=0.1),\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001),\n",
            "    clip_grad=dict(max_norm=40, norm_type=2))\n",
            "default_scope = 'mmaction'\n",
            "default_hooks = dict(\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=20, ignore_last=False),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook', interval=3, save_best='auto', max_keep_ckpts=3),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "log_level = 'INFO'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume = False\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = '/content/drive/MyDrive/dataset/train'\n",
            "data_root_val = '/content/drive/MyDrive/dataset/val'\n",
            "ann_file_train = '/content/drive/MyDrive/dataset/train.txt'\n",
            "ann_file_val = '/content/drive/MyDrive/dataset/val.txt'\n",
            "file_client_args = dict(io_backend='disk')\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=3),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='TenCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/train.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/train'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=3),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='TenCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=256)\n",
            "work_dir = './tutorial_exps'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmengine.runner import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.data_root = '/content/drive/MyDrive/dataset/train'\n",
        "cfg.data_root_val = '/content/drive/MyDrive/dataset/val'\n",
        "cfg.ann_file_train = '/content/drive/MyDrive/dataset/train.txt'\n",
        "cfg.ann_file_val = '/content/drive/MyDrive/dataset/val.txt'\n",
        "\n",
        "\n",
        "cfg.test_dataloader.dataset.ann_file = '/content/drive/MyDrive/dataset/val.txt'\n",
        "cfg.test_dataloader.dataset.data_prefix.video = '/content/drive/MyDrive/dataset/val'\n",
        "\n",
        "cfg.train_dataloader.dataset.ann_file = '/content/drive/MyDrive/dataset/train.txt'\n",
        "cfg.train_dataloader.dataset.data_prefix.video = '/content/drive/MyDrive/dataset/train'\n",
        "\n",
        "cfg.val_dataloader.dataset.ann_file = '/content/drive/MyDrive/dataset/val.txt'\n",
        "cfg.val_dataloader.dataset.data_prefix.video  = '/content/drive/MyDrive/dataset/val'\n",
        "\n",
        "# Modify num classes of the model in cls_head\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "# We can use the pre-trained TSN model\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16\n",
        "cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16\n",
        "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16\n",
        "cfg.train_cfg.max_epochs = 10\n",
        "\n",
        "cfg.train_dataloader.num_workers = 2\n",
        "cfg.val_dataloader.num_workers = 2\n",
        "cfg.test_dataloader.num_workers = 2\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install numpy --pre torch torchvision torchaudio --force-reinstall --index-url https://download.pytorch.org/whl/nightly/cu117"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRj9MHppLGut",
        "outputId": "cc48a33f-2a85-4e64-dfac-9aee4ae3bd96"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu117\n",
            "Collecting numpy\n",
            "  Downloading https://download.pytorch.org/whl/nightly/numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu117/torch-2.1.0.dev20230621%2Bcu117-cp310-cp310-linux_x86_64.whl (1886.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m425.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu117/torchvision-0.16.0.dev20230523%2Bcu117-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu117/torchaudio-2.1.0.dev20230523%2Bcu117-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting typing-extensions (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/networkx-3.0rc1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-triton==2.1.0+440fd1bf20 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-2.1.0%2B440fd1bf20-cp310-cp310-linux_x86_64.whl (93.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch and torchvision==0.16.0.dev20230523+cu117 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch\n",
            "    torchvision 0.16.0.dev20230523+cu117 depends on torch==2.1.0.dev20230523\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### Train a new recognizer\n",
        "\n",
        "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDBWkdDRk6oz",
        "outputId": "6ac7525c-d757-4da9-b15e-fbff60f34383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/28 02:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 647655066\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.8.2\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 647655066\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/28 02:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=400,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01,\n",
            "        average_clips='prob'),\n",
            "    data_preprocessor=dict(\n",
            "        type='ActionDataPreprocessor',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        format_shape='NCHW'),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "train_cfg = dict(\n",
            "    type='EpochBasedTrainLoop', max_epochs=100, val_begin=1, val_interval=1)\n",
            "val_cfg = dict(type='ValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=100,\n",
            "        by_epoch=True,\n",
            "        milestones=[\n",
            "            40,\n",
            "            80,\n",
            "        ],\n",
            "        gamma=0.1),\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001),\n",
            "    clip_grad=dict(max_norm=40, norm_type=2))\n",
            "default_scope = 'mmaction'\n",
            "default_hooks = dict(\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=20, ignore_last=False),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook', interval=3, save_best='auto', max_keep_ckpts=3),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = '/content/drive/MyDrive/dataset/train'\n",
            "data_root_val = '/content/drive/MyDrive/dataset/val'\n",
            "ann_file_train = '/content/drive/MyDrive/dataset/train.txt'\n",
            "ann_file_val = '/content/drive/MyDrive/dataset/val.txt'\n",
            "file_client_args = dict(io_backend='disk')\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=3),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='TenCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/train.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/train'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=3),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='TenCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "auto_scale_lr = dict(enable=True, base_batch_size=32)\n",
            "launcher = 'none'\n",
            "work_dir = './work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb'\n",
            "randomness = dict(seed=None, diff_rank_seed=False, deterministic=False)\n",
            "\n",
            "07/28 02:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/28 02:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "07/28 02:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - LR is set based on batch size of 32 and the current batch size is 32. Scaling the original LR by 1.0.\n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
            "07/28 02:04:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
            "07/28 02:04:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:04:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:04:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "07/28 02:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][10/10]  lr: 1.0000e-02  eta: 0:57:11  time: 3.4658  data_time: 2.2813  memory: 8222  grad_norm: 4.4263  loss: 5.3271  top1_acc: 0.4286  top5_acc: 0.7143  loss_cls: 5.3271\n",
            "07/28 02:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][3/3]    acc/top1: 0.4324  acc/top5: 0.8108  acc/mean1: 0.0909  data_time: 6.2059  time: 6.4683\n",
            "07/28 02:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.4324 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "07/28 02:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][10/10]  lr: 1.0000e-02  eta: 0:53:23  time: 3.2685  data_time: 2.2307  memory: 8221  grad_norm: 6.4220  loss: 4.2368  top1_acc: 0.4286  top5_acc: 0.7143  loss_cls: 4.2368\n",
            "07/28 02:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][3/3]    acc/top1: 0.1892  acc/top5: 0.8108  acc/mean1: 0.0909  data_time: 1.4229  time: 1.6403\n",
            "07/28 02:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][10/10]  lr: 1.0000e-02  eta: 0:51:14  time: 3.0216  data_time: 2.1215  memory: 8221  grad_norm: 6.7099  loss: 2.7288  top1_acc: 0.5714  top5_acc: 0.7143  loss_cls: 2.7288\n",
            "07/28 02:06:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "07/28 02:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][3/3]    acc/top1: 0.4459  acc/top5: 0.8108  acc/mean1: 0.0974  data_time: 1.4780  time: 1.6935\n",
            "07/28 02:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_1.pth is removed\n",
            "07/28 02:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.4459 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.\n",
            "07/28 02:06:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:06:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][10/10]  lr: 1.0000e-02  eta: 0:50:21  time: 3.0265  data_time: 2.1373  memory: 8221  grad_norm: 4.8487  loss: 2.0289  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 2.0289\n",
            "07/28 02:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][3/3]    acc/top1: 0.5541  acc/top5: 0.8649  acc/mean1: 0.1676  data_time: 1.4417  time: 1.6570\n",
            "07/28 02:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_3.pth is removed\n",
            "07/28 02:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5541 acc/top1 at 4 epoch is saved to best_acc_top1_epoch_4.pth.\n",
            "07/28 02:07:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:07:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][10/10]  lr: 1.0000e-02  eta: 0:49:22  time: 3.0410  data_time: 2.1542  memory: 8221  grad_norm: 4.7293  loss: 1.6298  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 1.6298\n",
            "07/28 02:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][3/3]    acc/top1: 0.6216  acc/top5: 0.8919  acc/mean1: 0.1935  data_time: 1.7010  time: 1.9223\n",
            "07/28 02:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_4.pth is removed\n",
            "07/28 02:07:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6216 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
            "07/28 02:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][10/10]  lr: 1.0000e-02  eta: 0:48:36  time: 3.0132  data_time: 2.1192  memory: 8221  grad_norm: 4.7012  loss: 1.4221  top1_acc: 0.5714  top5_acc: 0.7143  loss_cls: 1.4221\n",
            "07/28 02:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "07/28 02:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][3/3]    acc/top1: 0.6892  acc/top5: 0.9459  acc/mean1: 0.2727  data_time: 1.9498  time: 2.1721\n",
            "07/28 02:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_5.pth is removed\n",
            "07/28 02:08:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6892 acc/top1 at 6 epoch is saved to best_acc_top1_epoch_6.pth.\n",
            "07/28 02:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][10/10]  lr: 1.0000e-02  eta: 0:47:54  time: 3.0241  data_time: 2.1430  memory: 8221  grad_norm: 4.7724  loss: 1.2737  top1_acc: 0.4286  top5_acc: 0.8571  loss_cls: 1.2737\n",
            "07/28 02:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][3/3]    acc/top1: 0.7297  acc/top5: 0.9865  acc/mean1: 0.3653  data_time: 2.0085  time: 2.2259\n",
            "07/28 02:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_6.pth is removed\n",
            "07/28 02:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7297 acc/top1 at 7 epoch is saved to best_acc_top1_epoch_7.pth.\n",
            "07/28 02:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][10/10]  lr: 1.0000e-02  eta: 0:47:20  time: 3.0425  data_time: 2.1650  memory: 8221  grad_norm: 4.9748  loss: 1.1373  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 1.1373\n",
            "07/28 02:09:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][3/3]    acc/top1: 0.7568  acc/top5: 0.9865  acc/mean1: 0.3926  data_time: 1.8631  time: 2.0809\n",
            "07/28 02:09:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_7.pth is removed\n",
            "07/28 02:09:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7568 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
            "07/28 02:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][10/10]  lr: 1.0000e-02  eta: 0:46:35  time: 3.0042  data_time: 2.1268  memory: 8221  grad_norm: 4.9767  loss: 1.0451  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 1.0451\n",
            "07/28 02:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "07/28 02:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][3/3]    acc/top1: 0.7703  acc/top5: 0.9865  acc/mean1: 0.4305  data_time: 1.6271  time: 1.8456\n",
            "07/28 02:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_8.pth is removed\n",
            "07/28 02:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7703 acc/top1 at 9 epoch is saved to best_acc_top1_epoch_9.pth.\n",
            "07/28 02:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][10/10]  lr: 1.0000e-02  eta: 0:45:55  time: 2.9559  data_time: 2.0706  memory: 8221  grad_norm: 4.7967  loss: 0.9336  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.9336\n",
            "07/28 02:10:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][3/3]    acc/top1: 0.7973  acc/top5: 1.0000  acc/mean1: 0.4987  data_time: 1.5577  time: 1.7776\n",
            "07/28 02:10:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_9.pth is removed\n",
            "07/28 02:10:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7973 acc/top1 at 10 epoch is saved to best_acc_top1_epoch_10.pth.\n",
            "07/28 02:11:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:11:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][10/10]  lr: 1.0000e-02  eta: 0:45:14  time: 2.9525  data_time: 2.0552  memory: 8221  grad_norm: 4.9267  loss: 0.8403  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.8403\n",
            "07/28 02:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][3/3]    acc/top1: 0.8784  acc/top5: 1.0000  acc/mean1: 0.6515  data_time: 1.4524  time: 1.6713\n",
            "07/28 02:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_10.pth is removed\n",
            "07/28 02:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.8784 acc/top1 at 11 epoch is saved to best_acc_top1_epoch_11.pth.\n",
            "07/28 02:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][10/10]  lr: 1.0000e-02  eta: 0:44:37  time: 2.9462  data_time: 2.0436  memory: 8221  grad_norm: 5.1740  loss: 0.7790  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.7790\n",
            "07/28 02:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "07/28 02:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][3/3]    acc/top1: 0.8108  acc/top5: 0.9865  acc/mean1: 0.5485  data_time: 1.5177  time: 1.7351\n",
            "07/28 02:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][10/10]  lr: 1.0000e-02  eta: 0:43:52  time: 2.8943  data_time: 1.9813  memory: 8221  grad_norm: 5.3460  loss: 0.7360  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.7360\n",
            "07/28 02:12:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][3/3]    acc/top1: 0.8649  acc/top5: 1.0000  acc/mean1: 0.8066  data_time: 1.4739  time: 1.6939\n",
            "07/28 02:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][10/10]  lr: 1.0000e-02  eta: 0:43:13  time: 2.8581  data_time: 1.9530  memory: 8221  grad_norm: 5.6472  loss: 0.7623  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.7623\n",
            "07/28 02:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][3/3]    acc/top1: 0.8243  acc/top5: 1.0000  acc/mean1: 0.5636  data_time: 1.5517  time: 1.7723\n",
            "07/28 02:13:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:13:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][10/10]  lr: 1.0000e-02  eta: 0:42:37  time: 2.8998  data_time: 2.0161  memory: 8221  grad_norm: 5.6822  loss: 0.7178  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.7178\n",
            "07/28 02:13:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "07/28 02:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][3/3]    acc/top1: 0.8784  acc/top5: 1.0000  acc/mean1: 0.8040  data_time: 1.6093  time: 1.8308\n",
            "07/28 02:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][10/10]  lr: 1.0000e-02  eta: 0:42:03  time: 2.9190  data_time: 2.0435  memory: 8221  grad_norm: 5.3843  loss: 0.6502  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.6502\n",
            "07/28 02:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][3/3]    acc/top1: 0.8784  acc/top5: 1.0000  acc/mean1: 0.6455  data_time: 1.7649  time: 1.9834\n",
            "07/28 02:15:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:15:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][10/10]  lr: 1.0000e-02  eta: 0:41:26  time: 2.8963  data_time: 2.0017  memory: 8221  grad_norm: 5.2592  loss: 0.6064  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6064\n",
            "07/28 02:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.9062  data_time: 1.8966  time: 2.1138\n",
            "07/28 02:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_11.pth is removed\n",
            "07/28 02:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.9459 acc/top1 at 17 epoch is saved to best_acc_top1_epoch_17.pth.\n",
            "07/28 02:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][10/10]  lr: 1.0000e-02  eta: 0:40:52  time: 2.8910  data_time: 1.9916  memory: 8221  grad_norm: 5.1630  loss: 0.5629  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.5629\n",
            "07/28 02:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "07/28 02:16:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9364  data_time: 1.7174  time: 1.9319\n",
            "07/28 02:16:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_17.pth is removed\n",
            "07/28 02:16:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.9595 acc/top1 at 18 epoch is saved to best_acc_top1_epoch_18.pth.\n",
            "07/28 02:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][10/10]  lr: 1.0000e-02  eta: 0:40:19  time: 2.9114  data_time: 2.0238  memory: 8221  grad_norm: 5.1026  loss: 0.5334  top1_acc: 0.7143  top5_acc: 0.8571  loss_cls: 0.5334\n",
            "07/28 02:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.8636  data_time: 1.7965  time: 2.0128\n",
            "07/28 02:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][10/10]  lr: 1.0000e-02  eta: 0:39:47  time: 2.9260  data_time: 2.0342  memory: 8221  grad_norm: 5.8717  loss: 0.5431  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5431\n",
            "07/28 02:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.8608  data_time: 1.9422  time: 2.1606\n",
            "07/28 02:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][10/10]  lr: 1.0000e-02  eta: 0:39:11  time: 2.8749  data_time: 1.9897  memory: 8221  grad_norm: 6.3108  loss: 0.5621  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.5621\n",
            "07/28 02:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "07/28 02:17:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9409  data_time: 1.9752  time: 2.1934\n",
            "07/28 02:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][10/10]  lr: 1.0000e-02  eta: 0:38:38  time: 2.8441  data_time: 1.9563  memory: 8221  grad_norm: 5.3789  loss: 0.5171  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.5171\n",
            "07/28 02:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][3/3]    acc/top1: 0.9324  acc/top5: 1.0000  acc/mean1: 0.9506  data_time: 1.8067  time: 2.0233\n",
            "07/28 02:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][10/10]  lr: 1.0000e-02  eta: 0:38:06  time: 2.8958  data_time: 2.0078  memory: 8221  grad_norm: 4.6649  loss: 0.4787  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4787\n",
            "07/28 02:19:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.8608  data_time: 1.8032  time: 2.0213\n",
            "07/28 02:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][10/10]  lr: 1.0000e-02  eta: 0:37:38  time: 2.9652  data_time: 2.0870  memory: 8221  grad_norm: 4.6310  loss: 0.4609  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4609\n",
            "07/28 02:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "07/28 02:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][3/3]    acc/top1: 0.9324  acc/top5: 1.0000  acc/mean1: 0.8273  data_time: 2.2741  time: 2.4915\n",
            "07/28 02:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][10/10]  lr: 1.0000e-02  eta: 0:37:06  time: 2.9593  data_time: 2.0776  memory: 8221  grad_norm: 5.0869  loss: 0.4990  top1_acc: 0.7143  top5_acc: 0.8571  loss_cls: 0.4990\n",
            "07/28 02:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][3/3]    acc/top1: 0.9324  acc/top5: 1.0000  acc/mean1: 0.8318  data_time: 2.0547  time: 2.2684\n",
            "07/28 02:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][10/10]  lr: 1.0000e-02  eta: 0:36:38  time: 2.9698  data_time: 2.0898  memory: 8221  grad_norm: 5.2032  loss: 0.5158  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.5158\n",
            "07/28 02:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9517  data_time: 2.1437  time: 2.3617\n",
            "07/28 02:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][10/10]  lr: 1.0000e-02  eta: 0:36:07  time: 2.9769  data_time: 2.0851  memory: 8221  grad_norm: 4.9895  loss: 0.4865  top1_acc: 0.4286  top5_acc: 0.7143  loss_cls: 0.4865\n",
            "07/28 02:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "07/28 02:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9091  data_time: 2.2549  time: 2.4685\n",
            "07/28 02:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][10/10]  lr: 1.0000e-02  eta: 0:35:36  time: 2.9146  data_time: 2.0178  memory: 8221  grad_norm: 5.1984  loss: 0.4707  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4707\n",
            "07/28 02:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.8864  data_time: 1.8400  time: 2.0532\n",
            "07/28 02:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][10/10]  lr: 1.0000e-02  eta: 0:35:03  time: 2.8780  data_time: 1.9949  memory: 8221  grad_norm: 5.1540  loss: 0.4115  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4115\n",
            "07/28 02:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][3/3]    acc/top1: 0.9189  acc/top5: 1.0000  acc/mean1: 0.8424  data_time: 2.1541  time: 2.3699\n",
            "07/28 02:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][10/10]  lr: 1.0000e-02  eta: 0:34:30  time: 2.8191  data_time: 1.9263  memory: 8221  grad_norm: 4.4938  loss: 0.3338  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3338\n",
            "07/28 02:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "07/28 02:23:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.9733  data_time: 1.8583  time: 2.0724\n",
            "07/28 02:24:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:24:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][10/10]  lr: 1.0000e-02  eta: 0:33:59  time: 2.8575  data_time: 1.9702  memory: 8221  grad_norm: 4.7213  loss: 0.3262  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3262\n",
            "07/28 02:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9744  data_time: 2.0894  time: 2.3083\n",
            "07/28 02:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_18.pth is removed\n",
            "07/28 02:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.9730 acc/top1 at 31 epoch is saved to best_acc_top1_epoch_31.pth.\n",
            "07/28 02:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][10/10]  lr: 1.0000e-02  eta: 0:33:27  time: 2.8827  data_time: 2.0014  memory: 8221  grad_norm: 4.9628  loss: 0.3386  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3386\n",
            "07/28 02:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9015  data_time: 1.9331  time: 2.1487\n",
            "07/28 02:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][10/10]  lr: 1.0000e-02  eta: 0:32:59  time: 2.9234  data_time: 2.0482  memory: 8221  grad_norm: 4.5496  loss: 0.3443  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3443\n",
            "07/28 02:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "07/28 02:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][3/3]    acc/top1: 0.9459  acc/top5: 1.0000  acc/mean1: 0.8955  data_time: 2.1165  time: 2.3369\n",
            "07/28 02:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][10/10]  lr: 1.0000e-02  eta: 0:32:30  time: 2.9960  data_time: 2.1207  memory: 8221  grad_norm: 4.4130  loss: 0.3625  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3625\n",
            "07/28 02:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9818  data_time: 1.8122  time: 2.0284\n",
            "07/28 02:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_31.pth is removed\n",
            "07/28 02:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.9865 acc/top1 at 34 epoch is saved to best_acc_top1_epoch_34.pth.\n",
            "07/28 02:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][10/10]  lr: 1.0000e-02  eta: 0:31:58  time: 2.8952  data_time: 1.9749  memory: 8221  grad_norm: 4.2760  loss: 0.3483  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3483\n",
            "07/28 02:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9489  data_time: 1.9793  time: 2.1936\n",
            "07/28 02:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][10/10]  lr: 1.0000e-02  eta: 0:31:28  time: 2.8781  data_time: 1.9640  memory: 8221  grad_norm: 4.4823  loss: 0.3677  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3677\n",
            "07/28 02:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "07/28 02:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9136  data_time: 1.9239  time: 2.1382\n",
            "07/28 02:28:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:28:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][10/10]  lr: 1.0000e-02  eta: 0:30:57  time: 2.8956  data_time: 2.0099  memory: 8221  grad_norm: 4.4289  loss: 0.3446  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3446\n",
            "07/28 02:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9364  data_time: 2.1247  time: 2.3458\n",
            "07/28 02:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][10/10]  lr: 1.0000e-02  eta: 0:30:26  time: 2.8487  data_time: 1.9657  memory: 8221  grad_norm: 5.0184  loss: 0.3362  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3362\n",
            "07/28 02:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9744  data_time: 1.7478  time: 1.9668\n",
            "07/28 02:29:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:29:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][10/10]  lr: 1.0000e-02  eta: 0:29:55  time: 2.8771  data_time: 1.9801  memory: 8221  grad_norm: 4.7280  loss: 0.3453  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3453\n",
            "07/28 02:29:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "07/28 02:29:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][3/3]    acc/top1: 0.9595  acc/top5: 1.0000  acc/mean1: 0.9409  data_time: 1.8475  time: 2.0694\n",
            "07/28 02:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][10/10]  lr: 1.0000e-02  eta: 0:29:28  time: 2.9754  data_time: 2.0806  memory: 8221  grad_norm: 3.8743  loss: 0.3123  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3123\n",
            "07/28 02:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9818  data_time: 2.0199  time: 2.2387\n",
            "07/28 02:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][10/10]  lr: 1.0000e-03  eta: 0:28:58  time: 2.9815  data_time: 2.1036  memory: 8221  grad_norm: 4.4546  loss: 0.3532  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3532\n",
            "07/28 02:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9591  data_time: 1.9847  time: 2.2074\n",
            "07/28 02:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][10/10]  lr: 1.0000e-03  eta: 0:28:27  time: 2.8888  data_time: 2.0078  memory: 8221  grad_norm: 4.3933  loss: 0.3625  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3625\n",
            "07/28 02:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "07/28 02:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9591  data_time: 1.7688  time: 1.9895\n",
            "07/28 02:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][10/10]  lr: 1.0000e-03  eta: 0:27:58  time: 2.9221  data_time: 2.0444  memory: 8221  grad_norm: 3.7189  loss: 0.2912  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2912\n",
            "07/28 02:32:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9591  data_time: 1.6689  time: 1.8888\n",
            "07/28 02:32:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:32:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][10/10]  lr: 1.0000e-03  eta: 0:27:28  time: 2.9394  data_time: 2.0516  memory: 8221  grad_norm: 3.3258  loss: 0.2429  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2429\n",
            "07/28 02:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9591  data_time: 1.5895  time: 1.8091\n",
            "07/28 02:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][10/10]  lr: 1.0000e-03  eta: 0:26:59  time: 2.9342  data_time: 2.0332  memory: 8221  grad_norm: 3.1159  loss: 0.2262  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2262\n",
            "07/28 02:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "07/28 02:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 1.8227  time: 2.0396\n",
            "07/28 02:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][10/10]  lr: 1.0000e-03  eta: 0:26:33  time: 3.1137  data_time: 2.2080  memory: 8221  grad_norm: 3.3686  loss: 0.2417  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2417\n",
            "07/28 02:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 1.2245  time: 1.4442\n",
            "07/28 02:34:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:34:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][10/10]  lr: 1.0000e-03  eta: 0:26:04  time: 3.1017  data_time: 2.2063  memory: 8221  grad_norm: 3.4956  loss: 0.2457  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2457\n",
            "07/28 02:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 1.2546  time: 1.4748\n",
            "07/28 02:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][10/10]  lr: 1.0000e-03  eta: 0:25:34  time: 2.9231  data_time: 2.0403  memory: 8221  grad_norm: 3.6050  loss: 0.2508  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2508\n",
            "07/28 02:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "07/28 02:35:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 1.3567  time: 1.5717\n",
            "07/28 02:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][10/10]  lr: 1.0000e-03  eta: 0:25:04  time: 2.9016  data_time: 2.0171  memory: 8221  grad_norm: 3.5329  loss: 0.2363  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2363\n",
            "07/28 02:35:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][3/3]    acc/top1: 0.9730  acc/top5: 1.0000  acc/mean1: 0.9591  data_time: 1.5196  time: 1.7384\n",
            "07/28 02:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][10/10]  lr: 1.0000e-03  eta: 0:24:32  time: 2.8415  data_time: 1.9579  memory: 8221  grad_norm: 3.1645  loss: 0.2055  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2055\n",
            "07/28 02:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 1.7697  time: 1.9888\n",
            "07/28 02:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230728_020355\n",
            "07/28 02:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][10/10]  lr: 1.0000e-03  eta: 0:24:02  time: 2.8232  data_time: 1.9501  memory: 8221  grad_norm: 3.1986  loss: 0.1956  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.1956\n",
            "07/28 02:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 51 epochs\n",
            "07/28 02:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [51][3/3]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9773  data_time: 2.0648  time: 2.2818\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmaction2/tools/train.py\", line 135, in <module>\n",
            "    main()\n",
            "  File \"/content/mmaction2/tools/train.py\", line 131, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1735, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
            "    self.run_iter(idx, data_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 128, in run_iter\n",
            "    outputs = self.runner.model.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 116, in train_step\n",
            "    optim_wrapper.update_params(parsed_losses)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 205, in update_params\n",
            "    self.step(**step_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/scheduler/param_scheduler.py\", line 115, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 256, in step\n",
            "    self._clip_grad()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/optim/optimizer/optimizer_wrapper.py\", line 298, in _clip_grad\n",
            "    grad = self.clip_func(params, **self.clip_grad_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\", line 76, in clip_grad_norm_\n",
            "    torch._foreach_mul_(grads, clip_coef_clamped.to(device))  # type: ignore[call-overload]\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import mmengine\n",
        "from mmengine.runner import Runner\n",
        "CUDA_LAUNCH_BLOCKING = \"1\"\n",
        "# Create work_dir\n",
        "mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "\n",
        "# build the runner from config\n",
        "\n",
        "!python tools/train.py configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSd7oTLlxIf"
      },
      "source": [
        "### Understand the log\n",
        "From the log, we can have a basic understanding the training process and know how well the recognizer is trained.\n",
        "\n",
        "Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `fc.bias` and `fc.weight`.\n",
        "\n",
        "Second, since the dataset we are using is small, we loaded a TSN model and finetune it for action recognition.\n",
        "The original TSN is trained on original Kinetics-400 dataset which contains 400 classes but Kinetics-400 Tiny dataset only have 2 classes. Therefore, the last FC layer of the pre-trained TSN for classification has different weight shape and is not used.\n",
        "\n",
        "Third, after training, the recognizer is evaluated by the default evaluation. The results show that the recognizer achieves 100% top1 accuracy and 100% top5 accuracy on the val dataset,\n",
        "\n",
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## Test the trained recognizer\n",
        "\n",
        "After finetuning the recognizer, let's check the prediction results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eyY3hCMwyTct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7545a9b8-951e-4733-9e7c-d1ec216cd84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/28 02:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 565391950\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\n",
            "    PyTorch: 2.0.1+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.2+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.8.2\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 565391950\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/28 02:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=400,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01,\n",
            "        average_clips='prob'),\n",
            "    data_preprocessor=dict(\n",
            "        type='ActionDataPreprocessor',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        format_shape='NCHW'),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "train_cfg = dict(\n",
            "    type='EpochBasedTrainLoop', max_epochs=100, val_begin=1, val_interval=1)\n",
            "val_cfg = dict(type='ValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=100,\n",
            "        by_epoch=True,\n",
            "        milestones=[\n",
            "            40,\n",
            "            80,\n",
            "        ],\n",
            "        gamma=0.1),\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001),\n",
            "    clip_grad=dict(max_norm=40, norm_type=2))\n",
            "default_scope = 'mmaction'\n",
            "default_hooks = dict(\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=20, ignore_last=False),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook', interval=3, save_best='auto', max_keep_ckpts=3),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "log_level = 'INFO'\n",
            "load_from = '/content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth'\n",
            "resume = False\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = '/content/drive/MyDrive/dataset/train'\n",
            "data_root_val = '/content/drive/MyDrive/dataset/val'\n",
            "ann_file_train = '/content/drive/MyDrive/dataset/train.txt'\n",
            "ann_file_val = '/content/drive/MyDrive/dataset/val.txt'\n",
            "file_client_args = dict(io_backend='disk')\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=3),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    )),\n",
            "    dict(type='TenCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/train.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/train'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=3),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='/content/drive/MyDrive/dataset/val.txt',\n",
            "        data_prefix=dict(video='/content/drive/MyDrive/dataset/val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            )),\n",
            "            dict(type='TenCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "auto_scale_lr = dict(enable=True, base_batch_size=32)\n",
            "launcher = 'none'\n",
            "work_dir = './work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb'\n",
            "\n",
            "07/28 02:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/28 02:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loads checkpoint by local backend from path: /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth\n",
            "07/28 02:40:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:40:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/28 02:41:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [20/74]    eta: 0:01:11  time: 1.3263  data_time: 0.2493  memory: 2925  \n",
            "07/28 02:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [40/74]    eta: 0:00:37  time: 0.8830  data_time: 0.0134  memory: 2925  \n",
            "07/28 02:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [60/74]    eta: 0:00:14  time: 0.8427  data_time: 0.0134  memory: 2925  \n",
            "07/28 02:42:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [74/74]    acc/top1: 0.9865  acc/top5: 1.0000  acc/mean1: 0.9818  data_time: 0.0763  time: 0.9789\n"
          ]
        }
      ],
      "source": [
        "CUDA_VISIBLE_DEVICES=-1\n",
        "!python tools/test.py configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uY5LZ863eSH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f220e882-a405-4322-e1e8-fa5a818be402"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "from mmengine import Config\n",
        "TORCH_USE_CUDA_DSA=True\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = './configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'\n",
        "config = Config.fromfile(config)\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = '/content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Mm6K3LPYaAQx",
        "outputId": "d450afe3-aabf-461c-9514-6e847adec340"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: /content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8e0e639761d9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/mmaction2/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb/best_acc_top1_epoch_34.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize the recognizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_recognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/mmaction2/mmaction/apis/inference.py\u001b[0m in \u001b[0;36minit_recognizer\u001b[0;34m(config, checkpoint, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     def cuda(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the recognizer to do inference\n",
        "from operator import itemgetter\n",
        "video = '/content/mmaction2/kinetics400_tiny/train/27_CSXByd3s.mp4'\n",
        "label = '/content/mmaction2/kinetics400_tiny/label'\n",
        "results = inference_recognizer(model, video)\n",
        "\n",
        "pred_scores = results.pred_scores.item.tolist()\n",
        "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
        "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
        "top5_label = score_sorted[:5]\n",
        "\n",
        "labels = open(label).readlines()\n",
        "labels = [x.strip() for x in labels]\n",
        "y=0\n",
        "for x in pred_scores:\n",
        "  y+=1\n",
        "  print(y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rWSiffMaLLk",
        "outputId": "f72779cb-e249-42a8-b813-0433cf4275b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The top-5 labels with corresponding scores are:')\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "Po4IbWhUawYy",
        "outputId": "8ea2c4c3-12fc-4e41-d226-7052beff67d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top-5 labels with corresponding scores are:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d2c89e3b0bc5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The top-5 labels with corresponding scores are:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{result[0]}: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ActionDataSample' object is not iterable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "mmact_dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "189c342a4747645665e89db23000ac4d4edb7a87c4cd0b2f881610f468fb778d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}